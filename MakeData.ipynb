{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from conf import settings\n",
    "from utils import get_network, get_test_dataloader, get_training_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    def __init__(self):\n",
    "        self.net = 'vgg16'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "file_path = \"checkpoint/vgg16/Friday_04_March_2022_19h_25m_09s/vgg16-200-regular.pth\"\n",
    "\n",
    "class args:\n",
    "    def __init__(self):\n",
    "        self.net = 'vgg16'\n",
    "        self.gpu = True\n",
    "        self.b = 250\n",
    "        self.weights = file_path\n",
    "        \n",
    "args = args()\n",
    "net = get_network(args)\n",
    "\n",
    "cifar100_test_loader = get_test_dataloader(\n",
    "    settings.CIFAR100_TRAIN_MEAN,\n",
    "    settings.CIFAR100_TRAIN_STD,\n",
    "    #settings.CIFAR100_PATH,\n",
    "    num_workers=4,\n",
    "    batch_size=args.b,\n",
    ")\n",
    "\n",
    "net.load_state_dict(torch.load(args.weights))\n",
    "print(net)\n",
    "net.eval()\n",
    "\n",
    "correct_1 = 0.0\n",
    "correct_5 = 0.0\n",
    "total = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def normalize_max1(w):\n",
    "    for i in range(len(w)):\n",
    "        w[i] = w[i] / torch.max(abs(w[i]))\n",
    "    return w\n",
    "\n",
    "to_gaussian = lambda arr, mean = 1, std = 1: ((arr - torch.mean(arr))/ (torch.std(arr) + 0.00001)) * std + mean\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "softmax2d = lambda b: softmax(torch.flatten(b, start_dim = 1)).reshape(b.shape)\n",
    "f2 = lambda w, _=None: softmax2d(normalize_max1(-w)) * len(w[0])\n",
    "\n",
    "def normalize(img):\n",
    "    img = img- torch.min(img)\n",
    "    img /= (torch.max(img) + 0.01)\n",
    "    img = img* 255\n",
    "    return img.int()\n",
    "\n",
    "def change_format(img):\n",
    "    return torch.cat((img[2].unsqueeze(-1), img[1].unsqueeze(-1), img[0].unsqueeze(-1)), dim=-1)\n",
    "\n",
    "def image_unnormalize(img):\n",
    "    img = normalize(img)\n",
    "    img = change_format(img).cpu().detach().numpy().reshape(32,32,3)\n",
    "    return img\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 1 err:  tensor(0.2776, device='cuda:0')\n",
      "Top 5 err:  tensor(0.1021, device='cuda:0')\n",
      "Parameter numbers: 34015396\n",
      "\n",
      "Top 1 err:  tensor(0.0994, device='cuda:0')\n",
      "Top 5 err:  tensor(0.0313, device='cuda:0')\n",
      "Parameter numbers: 34015396\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "write_data = []\n",
    "\n",
    "correct_1 = 0.0\n",
    "correct_5 = 0.0\n",
    "total = 0\n",
    "\n",
    "correct_1_after = 0.0\n",
    "correct_5_after = 0.0\n",
    "\n",
    "for n_iter, (image, label) in enumerate(cifar100_test_loader):\n",
    "\n",
    "    if args.gpu:\n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "    image.requires_grad = True\n",
    "    image.retain_grad = True\n",
    "\n",
    "\n",
    "    output = net(image)\n",
    "\n",
    "    # calc acc\n",
    "    labels_origin = label.clone()\n",
    "    _, pred = output.topk(5, 1, largest=True, sorted=True)\n",
    "    label = label.view(label.size(0), -1).expand_as(pred)\n",
    "    correct = pred.eq(label).float()\n",
    "    correct_5 += correct[:, :5].sum()\n",
    "    correct_1 += correct[:, :1].sum()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    loss = criterion(output, labels_origin)\n",
    "    loss.backward()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "    img_lrp = (image*image.grad).clone()\n",
    "    img_lrp = f2(img_lrp)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(img_lrp)):\n",
    "            img_lrp[i] = to_gaussian(img_lrp[i], std = 0.02)\n",
    "\n",
    "        img_lrp = image*img_lrp # img_lrp가 음수값인것 지움\n",
    "        softlabel = net(img_lrp)\n",
    "\n",
    "        _, pred = softlabel.topk(5, 1, largest=True, sorted=True)\n",
    "        correct = pred.eq(label).float()\n",
    "        correct_5_after += correct[:, :5].sum()\n",
    "        correct_1_after += correct[:, :1].sum()\n",
    "\n",
    "\n",
    "    for it in range(len(img_lrp)):\n",
    "        write_pickle = {\n",
    "            \"label\" : labels_origin[it].item(),\n",
    "            \"softlabel\" : softlabel[it].cpu().numpy(),\n",
    "            \"img\" : image[it].detach().cpu().numpy(),\n",
    "            \"lrp_img\": img_lrp[it].detach().cpu().numpy()\n",
    "        }\n",
    "        write_data.append(write_pickle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Top 1 err: \", 1 - correct_1 / len(cifar100_test_loader.dataset))\n",
    "print(\"Top 5 err: \", 1 - correct_5 / len(cifar100_test_loader.dataset))\n",
    "print(\"Parameter numbers: {}\".format(sum(p.numel() for p in net.parameters())))\n",
    "\n",
    "print()\n",
    "print(\"Top 1 err: \", 1 - correct_1_after / len(cifar100_test_loader.dataset))\n",
    "print(\"Top 5 err: \", 1 - correct_5_after / len(cifar100_test_loader.dataset))\n",
    "print(\"Parameter numbers: {}\\n\\n\".format(sum(p.numel() for p in net.parameters())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 10799.23it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for idx, d in enumerate(tqdm(write_data)):\n",
    "    with open(\"LRP_Data/test/\" + str(idx).zfill(6) + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(d, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
